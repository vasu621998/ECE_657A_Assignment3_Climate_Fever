{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "closed-transcription",
   "metadata": {},
   "source": [
    "# <div align=\"center\">CM1</div>\n",
    "\n",
    "\n",
    "###  1.1 Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "brave-clear",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import gensim.downloader as api\n",
    "from datasets import load_dataset\n",
    "from scipy import spatial\n",
    "import math\n",
    "from gensim import models\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-colors",
   "metadata": {},
   "source": [
    "### 1.2 Load dataset \n",
    "\n",
    "- Identified there are large number of null values exist in columns, so in this assignment we have verified that there will be very less data exist if we remove null values.\n",
    "\n",
    "- Moreover we will focus on text dataset to build a model. Hence there is no good reason to normalise or remove nll values.\n",
    "\n",
    "\n",
    "**Dataset Overview :**\n",
    "\n",
    "- Climate Fever dataset uses Fever methodology that consists of 1,535 real-world claims regarding climate-change collected on the internet.\n",
    "\n",
    "- Each claim is accompanied by five manually annotated evidence ( Evidence 0 to 4 ) sentences retrieved from the  Wikipedia that support, refute or do not give enough information to validate the claim.\n",
    "\n",
    "**Dataset Feature :**\n",
    "\n",
    "1) claim_id : An unique claim identifier in datset.\n",
    "2) claim :  claim text.\n",
    "3) claim_label :   Overall label assigned to claim (based on evidence majority vote), The label correspond to 0: \"refutes\", 1: \"supports\" and 2: \"not enough info\".\n",
    "4) evidences : A list of evidences with below fields : \n",
    "    1. evidence_id : An unique evidence identifier.\n",
    "    2. evidence_label : A micro-verdict label, The label correspond to 0: \"refutes\", 1: \"supports\" and 2: \"not enough info\".\n",
    "    3. article : A title of source article (Wikipedia page).\n",
    "    4. evidence : An evidence sentence.\n",
    "    5. entropy : An entropy reflecting uncertainty of evidence_label.\n",
    "    6. votes : Refers to individual votes.\n",
    "    \n",
    "    \n",
    "**Note :** In each claim there are total 5 evidences avaialbke in dataset ( From evidence 0 to 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sorted-intensity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset climate_fever (C:\\Users\\DELL\\.cache\\huggingface\\datasets\\climate_fever\\default\\1.0.1\\3b846b20d7a37bc0019b0f0dcbde5bf2d0f94f6874f7e4c398c579f332c4262c)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim_id', 'claim', 'claim_label', 'evidences'],\n",
       "    num_rows: 1535\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('climate_fever')\n",
    "dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-access",
   "metadata": {},
   "source": [
    "### 1.3 Assigned claim  and evidence feature values to corpus ( In order to to apply word embedding )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "turned-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_list = list()\n",
    "for i in range(0, dataset[\"test\"].num_rows):\n",
    "    claim = dataset[\"test\"][i][\"claim\"]\n",
    "    sent_list.append(claim)\n",
    "   \n",
    "    for _, data in enumerate(dataset[\"test\"][i][\"evidences\"]):\n",
    "        article = data[\"article\"]\n",
    "        evidence = data[\"evidence\"]\n",
    "        sent_list.append(article)\n",
    "        sent_list.append(evidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-escape",
   "metadata": {},
   "source": [
    "### 1.4 Text/Data Preprocessing :\n",
    "\n",
    "- NLTK :\n",
    "    - We used nltk.corpus package and stopwords library to remove stopwords from corpus.\n",
    "- PorterStemmer :\n",
    "    - Stemming is the process of producing morphological variants of a root/base word.\n",
    "    - Stemming programs are commonly referred to as stemming algorithms or stemmers. A stemming algorithm reduces the words “chocolates”, “chocolatey”, “choco” to the root word, “chocolate”.\n",
    "    \n",
    "**Errors in Stemming :**\n",
    "There are mainly two errors in stemming – **Overstemming** and **Understemming**. \n",
    "- Overstemming occurs when two words are stemmed to same root that are of different stems. \n",
    "- Under-stemming occurs when two words are stemmed to same root that are not of different stems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "curious-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "claim_corpus = []\n",
    "\n",
    "for i in range (0,1534):\n",
    "    sentences = re.sub('[^a-zA-z]',' ', sent_list[i])\n",
    "    sentences = sentences.lower()\n",
    "    sentences = sentences.split()\n",
    "    ps = PorterStemmer()\n",
    "    all_stopwords = stopwords.words('english')\n",
    "    all_stopwords.remove('not')\n",
    "    sentences = [ps.stem(word) for word in sentences if not word in set(all_stopwords)]\n",
    "    sentences = ' '.join(sentences)\n",
    "    claim_corpus.append(sentences)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-tissue",
   "metadata": {},
   "source": [
    "### 1.5 Converted every word of the corpus to embedding vectors in order to embed the text dataset with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "indian-window",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusVec = [nltk.word_tokenize(sentences) for sentences in claim_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-penguin",
   "metadata": {},
   "source": [
    "### 1.6 Build a word2Vec model\n",
    "\n",
    "- Word2Vec model maps words to real number vectors, at the same time capturing something about the meaning of the text. It says that if two words have similar meaning they will lie close to each other in the dense space. \n",
    "- Word2Vec model contains two models for training Skip-Gram model and continuous bag of words(CBOW).\n",
    "\n",
    "**Parameters :**\n",
    "- min_count (int) – Ignores all words with total frequency lower than min_count value\n",
    "- size (int) – Dimensionality of the feature vectors.\n",
    "- window (int) – The maximum distance between the current and predicted word within a sentence.\n",
    "- seed (int) – Seed for the random number generator. Initial vectors for each word are seeded with a hash of the concatenation of word + str(seed).\n",
    "\n",
    "**Note :**\n",
    "- We have build a Word2vec model on entire dataset and then after we have split word embeddings into train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "brazilian-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(corpusVec,  min_count =1)\n",
    "model.save(\"word2vec.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-google",
   "metadata": {},
   "source": [
    "### 1.7 Split word embeddings into train and test sets\n",
    "\n",
    "- Train set (corpusVec_train) contains 80% of word embeddings.\n",
    "- Test set (corpusVec_test) contains 20% of word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "political-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusVec_train, corpusVec_test = train_test_split(corpusVec,test_size=0.20,random_state = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-reflection",
   "metadata": {},
   "source": [
    "#### 1.7.1 Created dictionaries to store word and it's embedding\n",
    "\n",
    "- 2 dictionaries are created ( 1 for train set and another for test set)\n",
    "- As a window_size in Word2Vec model is 100 (default value) for each word there will be 100 numbers attached to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "smooth-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_train = dict()\n",
    "embedding_test = dict()\n",
    "\n",
    "\n",
    "for sentence in corpusVec_train:\n",
    "    for word in sentence:\n",
    "        embedding_train[word] = model.wv[word]\n",
    "        \n",
    "for sentence in corpusVec_test:\n",
    "    for word in sentence:\n",
    "        embedding_test[word] = model.wv[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "injured-lighter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2194"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_train.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "average-annotation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1006"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-finland",
   "metadata": {},
   "source": [
    "#### 1.7.2 Created train and test dataframe from embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "demanding-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb_df = pd.DataFrame.from_dict(embedding_train)\n",
    "test_emb_df = pd.DataFrame.from_dict(embedding_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ceramic-enhancement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>present</th>\n",
       "      <th>primari</th>\n",
       "      <th>sourc</th>\n",
       "      <th>co</th>\n",
       "      <th>emiss</th>\n",
       "      <th>burn</th>\n",
       "      <th>coal</th>\n",
       "      <th>natur</th>\n",
       "      <th>ga</th>\n",
       "      <th>petroleum</th>\n",
       "      <th>...</th>\n",
       "      <th>judaism</th>\n",
       "      <th>demograph</th>\n",
       "      <th>done</th>\n",
       "      <th>halt</th>\n",
       "      <th>bar</th>\n",
       "      <th>mpa</th>\n",
       "      <th>dedic</th>\n",
       "      <th>polit</th>\n",
       "      <th>landfil</th>\n",
       "      <th>bioga</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.001782</td>\n",
       "      <td>0.005648</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.009453</td>\n",
       "      <td>0.015537</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.004776</td>\n",
       "      <td>0.009171</td>\n",
       "      <td>0.006098</td>\n",
       "      <td>0.003724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000942</td>\n",
       "      <td>-0.003625</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>-0.001295</td>\n",
       "      <td>-0.000734</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>-0.002161</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0.004523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.010028</td>\n",
       "      <td>-0.001798</td>\n",
       "      <td>-0.004617</td>\n",
       "      <td>-0.034945</td>\n",
       "      <td>-0.035831</td>\n",
       "      <td>-0.011301</td>\n",
       "      <td>-0.006917</td>\n",
       "      <td>-0.037424</td>\n",
       "      <td>-0.021329</td>\n",
       "      <td>-0.002396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002988</td>\n",
       "      <td>-0.001905</td>\n",
       "      <td>-0.005544</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>-0.004576</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>-0.002630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011174</td>\n",
       "      <td>0.005265</td>\n",
       "      <td>0.006674</td>\n",
       "      <td>0.028128</td>\n",
       "      <td>0.034854</td>\n",
       "      <td>0.006606</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>0.027529</td>\n",
       "      <td>0.019020</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004009</td>\n",
       "      <td>-0.003461</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.005062</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>-0.002214</td>\n",
       "      <td>-0.001386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.009948</td>\n",
       "      <td>-0.008878</td>\n",
       "      <td>-0.009909</td>\n",
       "      <td>-0.045867</td>\n",
       "      <td>-0.047601</td>\n",
       "      <td>-0.007597</td>\n",
       "      <td>-0.008281</td>\n",
       "      <td>-0.034950</td>\n",
       "      <td>-0.031299</td>\n",
       "      <td>-0.011499</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004152</td>\n",
       "      <td>-0.003903</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>-0.004872</td>\n",
       "      <td>-0.003172</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>-0.006210</td>\n",
       "      <td>-0.002827</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.008551</td>\n",
       "      <td>-0.006092</td>\n",
       "      <td>-0.015271</td>\n",
       "      <td>-0.046082</td>\n",
       "      <td>-0.044224</td>\n",
       "      <td>-0.009806</td>\n",
       "      <td>-0.002780</td>\n",
       "      <td>-0.040721</td>\n",
       "      <td>-0.028435</td>\n",
       "      <td>-0.011022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>-0.005975</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>-0.004393</td>\n",
       "      <td>-0.004838</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>-0.005316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    present   primari     sourc        co     emiss      burn      coal  \\\n",
       "0 -0.001782  0.005648  0.003972  0.009453  0.015537  0.000564  0.004776   \n",
       "1 -0.010028 -0.001798 -0.004617 -0.034945 -0.035831 -0.011301 -0.006917   \n",
       "2  0.011174  0.005265  0.006674  0.028128  0.034854  0.006606  0.004920   \n",
       "3 -0.009948 -0.008878 -0.009909 -0.045867 -0.047601 -0.007597 -0.008281   \n",
       "4 -0.008551 -0.006092 -0.015271 -0.046082 -0.044224 -0.009806 -0.002780   \n",
       "\n",
       "      natur        ga  petroleum  ...   judaism  demograph      done  \\\n",
       "0  0.009171  0.006098   0.003724  ... -0.000942  -0.003625  0.002108   \n",
       "1 -0.037424 -0.021329  -0.002396  ... -0.002988  -0.001905 -0.005544   \n",
       "2  0.027529  0.019020   0.001535  ...  0.004009  -0.003461  0.000587   \n",
       "3 -0.034950 -0.031299  -0.011499  ... -0.004152  -0.003903  0.000796   \n",
       "4 -0.040721 -0.028435  -0.011022  ...  0.000291  -0.005975  0.002808   \n",
       "\n",
       "       halt       bar       mpa     dedic     polit   landfil     bioga  \n",
       "0  0.004000 -0.001295 -0.000734  0.004902 -0.002161  0.002322  0.004523  \n",
       "1  0.002553  0.000243  0.001047 -0.004576  0.000349  0.002963 -0.002630  \n",
       "2  0.005062  0.000890  0.003953  0.002531  0.000641 -0.002214 -0.001386  \n",
       "3 -0.004872 -0.003172  0.002968 -0.006210 -0.002827  0.001878  0.002500  \n",
       "4 -0.004393 -0.004838  0.004040  0.003215  0.001921  0.001409 -0.005316  \n",
       "\n",
       "[5 rows x 2194 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "revised-airline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=2397, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-ireland",
   "metadata": {},
   "source": [
    "#### 1.7.3 Features of Word2Vec :\n",
    "\n",
    "- After the model is trained, it is accessible via the “wv” attribute..This is the actual word vector model in which queries can be made.\n",
    "- We can also save and load out Word2Vec model using \"model.save(\"word2vec.bin\")\" and \"model = Word2Vec.load('model.bin')\" respectively.\n",
    "- We can print the learned vocabulary of tokens (words) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "positive-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = model.wv.vocab\n",
    "# print(words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-fifth",
   "metadata": {},
   "source": [
    "### 1.8 Cosine Similarity Function ( In order to calulate text similarity ): \n",
    "\n",
    "- Among different distance metrics, cosine similarity is more intuitive and most used in word2vec. It is normalized dot product of 2 vectors and this ratio defines the angle between them.\n",
    "- Cosine similiarity between two vectors (A and B) can be calculated using dot(A, B)/(norm(A)*norm(B)). Here norm(A) and norm(B) indicates euclidean norm of vectors respectively.\n",
    "\n",
    "**Note :** In order to build a function for cosine similarity we used scipy.spatial.distance.cosine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "missing-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(v1, v2):\n",
    "    return abs(1 - spatial.distance.cosine(v1,v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-bracelet",
   "metadata": {},
   "source": [
    "#### 1.8.1 Cosine Similarity Function Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "clinical-nigeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between 'slower'and 'global' is : 0.6261319518089294\n",
      "Cosine Similarity between 'high'and 'low' is : 0.9467276334762573\n",
      "Cosine Similarity between 'peopl'and 'human' is : 0.8716719150543213\n",
      "Cosine Similarity between 'australia'and 'warm' is : 0.9703410267829895\n",
      "Cosine Similarity between 'scientists'and 'guidelin' is : 0.09903361648321152\n"
     ]
    }
   ],
   "source": [
    "ex1 = cos_similarity(embedding_train[\"slower\"], embedding_train[\"global\"])\n",
    "ex2 = cos_similarity(embedding_train[\"high\"], embedding_train[\"low\"])\n",
    "ex3 = cos_similarity(embedding_train[\"peopl\"], embedding_train[\"human\"])\n",
    "ex4 = cos_similarity(embedding_train[\"australia\"], embedding_train[\"warm\"])\n",
    "ex5 = cos_similarity(embedding_train[\"scientists\"], embedding_train[\"guidelin\"])\n",
    "print(f\"Cosine Similarity between 'slower'and 'global' is : {ex1}\")\n",
    "print(f\"Cosine Similarity between 'high'and 'low' is : {ex2}\")\n",
    "print(f\"Cosine Similarity between 'peopl'and 'human' is : {ex3}\")\n",
    "print(f\"Cosine Similarity between 'australia'and 'warm' is : {ex4}\")\n",
    "print(f\"Cosine Similarity between 'scientists'and 'guidelin' is : {ex5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-antigua",
   "metadata": {},
   "source": [
    "#### 1.8.2 Analysis of Cosine Similarity \n",
    "\n",
    "- Cosine Similarity measured by the cosine of **the angle between two vectors** and determines whether two vectors are pointing in roughly the same direction or not.\n",
    "- This similarity score ranges from 0 to 1, with 0 being the lowest (the least similar) and 1 being the highest (the most similar).\n",
    "-  A cosine value of 0 means that the two vectors are at 90 degrees to each other (orthogonal) and have no match. \n",
    "- The closer the cosine value to 1, the smaller the angle and the greater the match between vectors.\n",
    "- From above examples and embedded vector for a specific token ( model.wv[word] ) it is cleared that **more difference** between embedded vector for a specific token then lower value for cosine simillarity. ( for example scientists and guidelin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-sensitivity",
   "metadata": {},
   "source": [
    "### 1.9 Airthmetic computations on embedding vectors\n",
    "\n",
    "- After successfully build a Word2Vec model, we can do create a little linear algebra arithmetic with words.\n",
    "- Gensim provides an interface for performing these types of operations in the most_similar() function on the trained or loaded model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-treatment",
   "metadata": {},
   "source": [
    "Example 1 : **ocean - water + arctic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "decent-india",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('may', 0.7864083051681519),\n",
       " ('region', 0.7860227823257446),\n",
       " ('potenti', 0.7854949235916138),\n",
       " ('end', 0.7844065427780151),\n",
       " ('energi', 0.784231424331665),\n",
       " ('averag', 0.7840951085090637),\n",
       " ('core', 0.7837210893630981),\n",
       " ('releas', 0.7836814522743225),\n",
       " ('recent', 0.7832280397415161),\n",
       " ('rate', 0.7821105122566223)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['ocean', 'arctic'], negative=['water'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-muscle",
   "metadata": {},
   "source": [
    "Example 2 :  **extrem - weather + temperatur** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "serial-rocket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mean', 0.9193539619445801),\n",
       " ('rate', 0.9187940359115601),\n",
       " ('human', 0.9180346131324768),\n",
       " ('ice', 0.9178087115287781),\n",
       " ('c', 0.9177825450897217),\n",
       " ('ga', 0.9171391725540161),\n",
       " ('year', 0.9167925715446472),\n",
       " ('increas', 0.9164981842041016),\n",
       " ('world', 0.9162797927856445),\n",
       " ('climat', 0.9155672788619995)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['extrem', 'temperatur'], negative=['weather'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-phrase",
   "metadata": {},
   "source": [
    "Example 3: **'heat' - 'rise' + 'cold'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "labeled-violation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('extrem', 0.9505780935287476),\n",
       " ('would', 0.9499229788780212),\n",
       " ('c', 0.9487543106079102),\n",
       " ('sinc', 0.9486084580421448),\n",
       " ('surfac', 0.9485632181167603),\n",
       " ('caus', 0.9478595852851868),\n",
       " ('recent', 0.9478594064712524),\n",
       " ('f', 0.9477652311325073),\n",
       " ('report', 0.9471041560173035),\n",
       " ('natur', 0.9470906257629395)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['heat', 'cold', 'warm'], negative=['rise'])\n",
    "#model.wv.most_similar('heat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-liabilities",
   "metadata": {},
   "source": [
    "Example 4 : **'high' - 'temperatur' + 'heat'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "monthly-assets",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('emiss', 0.9673811197280884),\n",
       " ('like', 0.9671779870986938),\n",
       " ('co', 0.966587483882904),\n",
       " ('climat', 0.9659023284912109),\n",
       " ('warm', 0.9659013152122498),\n",
       " ('use', 0.9655390977859497),\n",
       " ('weather', 0.9654750823974609),\n",
       " ('averag', 0.9652884602546692),\n",
       " ('increas', 0.9649722576141357),\n",
       " ('result', 0.9646478891372681)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['high', 'heat'], negative=['temperatur'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-welding",
   "metadata": {},
   "source": [
    "Example 5 : **'climat' + 'chang' + 'temperatur'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "difficult-southwest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('increas', 0.9970048666000366),\n",
       " ('caus', 0.9969384074211121),\n",
       " ('co', 0.9964942932128906),\n",
       " ('human', 0.9958808422088623),\n",
       " ('year', 0.9957847595214844),\n",
       " ('c', 0.9956972599029541),\n",
       " ('carbon', 0.995648980140686),\n",
       " ('use', 0.9955489635467529),\n",
       " ('global', 0.9954564571380615),\n",
       " ('emiss', 0.995436429977417)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['climat', 'chang', 'temperatur'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-bumper",
   "metadata": {},
   "source": [
    "Example 6 : **'hurrican' - 'storm' + 'wind'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "american-sense",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('world', 0.8534212112426758),\n",
       " ('carbon', 0.8465461134910583),\n",
       " ('reduc', 0.8461534976959229),\n",
       " ('industri', 0.8460868000984192),\n",
       " ('scientist', 0.8454304933547974),\n",
       " ('model', 0.8453484177589417),\n",
       " ('oxygen', 0.8450800776481628),\n",
       " ('year', 0.8444372415542603),\n",
       " ('earth', 0.843956708908081),\n",
       " ('natur', 0.8435795307159424)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['hurrican', 'wind'], negative=['storm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-richmond",
   "metadata": {},
   "source": [
    "#### 1.9.1 Analysis of airthmetic computations on the embedding vectors :\n",
    "\n",
    "- From above 5 example, it is clear that our model will not able to identify correct words that we are looking for, However similarity score are also very high.\n",
    "- In some airthmetic computations our model able to identify correct ( upto some extent ) word such as in example 4 (climat + chang + temperatur = increase with similarity score 0.997 but not able to identify word 'decrease').\n",
    "\n",
    "\n",
    "**Most similar output for above example from our model :**\n",
    "\n",
    "1. ocean - water + arctic = region\n",
    "2. extrem - weather + temperatur = increase ( 1st most similar word is not related )\n",
    "3. heat - rise + cold  = extrem ( Excepted is decrease )\n",
    "4. high - temperatur + heat = warm\n",
    "5. climat + chang + temperatur = increas ( Decrease is not able to idenitfied bby model )\n",
    "6. hurrican - storm + wind = decrese ( Ideally model should return increase )\n",
    "\n",
    "**Note :** In order to get all most similar words I haven't used topn feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-donna",
   "metadata": {},
   "source": [
    "### 1.10 Examples to find similarity between 2 words: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "broke-prefix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between words 'high' and 'low' is : 0.9467276334762573\n",
      "Similarity between words 'peopl' and 'human' is : 0.8716719746589661\n",
      "Similarity between words 'extrem' and 'weather' is : 0.9901080131530762\n",
      "Similarity between words 'australia' and 'warm' is : 0.9703410267829895\n",
      "Similarity between words 'australia' and 'warm' is : 0.992263913154602\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Similarity between words 'high' and 'low' is : {model.wv.similarity('high', 'low')}\")\n",
    "print(f\"Similarity between words 'peopl' and 'human' is : {model.wv.similarity('peopl', 'human')}\")\n",
    "print(f\"Similarity between words 'extrem' and 'weather' is : {model.wv.similarity('extrem', 'weather')}\")\n",
    "print(f\"Similarity between words 'australia' and 'warm' is : {model.wv.similarity('australia', 'warm')}\")\n",
    "print(f\"Similarity between words 'australia' and 'warm' is : {model.wv.similarity('heat', 'water')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-barrier",
   "metadata": {},
   "source": [
    "### 1.11 Loaded pretrained model and performed \n",
    "\n",
    "We have loaded below pretrained models :\n",
    "\n",
    "1. glove-wiki-gigaword-50 model\n",
    "2. GoogleNewsvectorsnegative300 Model\n",
    "3. glove-twitter-25 model\n",
    "\n",
    "#### 1.11.1  glove-wiki-gigaword-50 model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "vocal-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_model1 = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "prime-flower",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('temperature', 0.7556608319282532),\n",
       " ('cold', 0.7549160718917847),\n",
       " ('temperatures', 0.7502944469451904),\n",
       " ('humidity', 0.7431684732437134),\n",
       " ('hot', 0.7388110160827637),\n",
       " ('moisture', 0.7275059819221497),\n",
       " ('chill', 0.7268701195716858),\n",
       " ('water', 0.7164075970649719),\n",
       " ('heating', 0.7090611457824707),\n",
       " ('add', 0.7034947872161865)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_model1.most_similar('heat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-suspect",
   "metadata": {},
   "source": [
    "**Example 1 in Pretrained model :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "original-demographic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('antarctica', 0.832500159740448),\n",
       " ('antarctic', 0.7697972655296326),\n",
       " ('polar', 0.7220200896263123)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_model1.most_similar(positive=['ocean', 'arctic'], negative=['water'], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-radio",
   "metadata": {},
   "source": [
    "**Example 2 in Pretrained model :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "victorian-demographic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('absorption', 0.7154293060302734),\n",
       " ('polarization', 0.702642560005188),\n",
       " ('weight', 0.7001583576202393)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_model1.most_similar(positive=['extreme', 'temperature'], negative=['weather'], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-translator",
   "metadata": {},
   "source": [
    "**Example 3 in Pretrained model :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "liquid-washer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cool', 0.7649688720703125),\n",
       " ('chill', 0.7594031095504761),\n",
       " ('hot', 0.7589381337165833)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_model1.most_similar(positive=['heat', 'cold', 'warm'], negative=['rise'], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-drink",
   "metadata": {},
   "source": [
    "**Example 4 in Pretrained model :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "phantom-spelling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('home', 0.7420942187309265),\n",
       " ('over', 0.7382623553276062),\n",
       " ('while', 0.7318180799484253)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_model1.most_similar(positive=['high', 'heat'], negative=['temperature'], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-excess",
   "metadata": {},
   "source": [
    "**Example 5 in Pretrained model :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "focused-provincial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('changes', 0.8372025489807129),\n",
       " ('conditions', 0.8201982975006104),\n",
       " ('impact', 0.8165292739868164)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_model1.most_similar(positive=['climate', 'change', 'temperature'], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-lender",
   "metadata": {},
   "source": [
    "**Example 6 in Pretrained model :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "suburban-joining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('winds', 0.7835291624069214),\n",
       " ('gusts', 0.7169768810272217),\n",
       " ('sound', 0.6997408866882324)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_model1.most_similar(positive=['hurricane', 'wind'], negative=['storm'], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-discount",
   "metadata": {},
   "source": [
    "#### 1.11.2  GoogleNews-vectors-negative300 model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "\n",
    "pr_model2 = gensim.models.KeyedVectors.load_word2vec_format('GoogleNewsvectorsnegative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-danger",
   "metadata": {},
   "source": [
    "**Example 1 to 5 on GoogleNews-vectors-negative300 model :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "recreational-leeds",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('zeppelin', 0.8628155589103699),\n",
       " ('dragons', 0.8590071797370911),\n",
       " ('castle', 0.8434920310974121)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_model2.most_similar(positive=['ocean', 'arctic'], negative=['water'], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "sixth-danish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('capacity', 0.8226763606071472),\n",
       " ('variable', 0.8071826696395874),\n",
       " ('velocity', 0.8006629943847656)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_model2.most_similar(positive=['extreme', 'temperature'], negative=['weather'], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "recovered-wallace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wet', 0.8819375038146973),\n",
       " ('freezing', 0.844189465045929),\n",
       " ('dry', 0.8343328237533569)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_model3.most_similar(positive=['heat', 'cold', 'warm'], negative=['rise'], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "conceptual-lightweight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('beat', 0.9010361433029175),\n",
       " ('play', 0.8993435502052307),\n",
       " ('boys', 0.8965255618095398)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_model3.most_similar(positive=['high', 'heat'], negative=['temperature'], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "marine-notice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('beat', 0.9010361433029175),\n",
       " ('play', 0.8993435502052307),\n",
       " ('boys', 0.8965255618095398)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_model3.most_similar(positive=['high', 'heat'], negative=['temperature'], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-bobby",
   "metadata": {},
   "source": [
    "#### 1.11.3 Glove-twitter-25 model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "harmful-pacific",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pr_model3 = api.load(\"glove-twitter-25\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "another-purpose",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('thunder', 0.9267944097518921),\n",
       " ('bulls', 0.911600649356842),\n",
       " ('ball', 0.9085021615028381),\n",
       " ('beat', 0.9076730012893677),\n",
       " ('playoffs', 0.8956629037857056),\n",
       " ('lakers', 0.8936164379119873),\n",
       " ('basketball', 0.8829619884490967),\n",
       " ('cowboys', 0.8791283965110779),\n",
       " ('baseball', 0.8777887225151062),\n",
       " ('celtics', 0.8775449991226196)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_model3.most_similar('heat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-defensive",
   "metadata": {},
   "source": [
    "### 1.12 Analysis of pre-trained models :\n",
    "\n",
    "From above outputs and with compare to our model's output we can clearly conclude few points :\n",
    "\n",
    "- Similarity score in our model are very high compare to pretrained model but we are not able to get accurate result in our model.\n",
    "- In pre-trained model similarity score is low compare to our model because pretrained model built upon large dataset.\n",
    "- Using pre-trained model we can also compare how efficient our model is.\n",
    "\n",
    "**Note:** As pre-trained model have large dataset we can't predict excepted values from most_similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-cedar",
   "metadata": {},
   "source": [
    "### 1.13 Difference between most_similar and similar_by_vector :\n",
    "\n",
    "- The most_similar similar function retrieves the vectors corresponding to \"king\", \"woman\" and \"man\", and normalizes them before computing king - man + woman.\n",
    "- The function call model.similar_by_vector(v) just calls model.most_similar(positive=[v])."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
